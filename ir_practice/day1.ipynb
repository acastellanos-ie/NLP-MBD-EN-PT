{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zc4KKv4uR2TU"
   },
   "source": [
    "# Information Retrieval Practice\n",
    "\n",
    "Elasticsearch is an open-source distributed search server built on top of Apache Lucene. Itâ€™s a great tool that allows to quickly build applications with full-text search capabilities. The core implementation is in Java, but it provides a nice REST interface which allows to interact with Elasticsearch from any programming language.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y94Tw5_sR2TY"
   },
   "source": [
    "## Install Elastic Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_zghOWrR2TZ"
   },
   "source": [
    "To install elastic search download your the package for your platform from Get Elasticsearch\n",
    " in https://www.elastic.co/es/start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hEFHWtw9R2Ta"
   },
   "source": [
    "![](https://github.com/acastellanos-ie/natural_language_processing/blob/master/ir_practice/download.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_hMXNaPR2Ta"
   },
   "source": [
    "Once downloaded, unzip the tar.gz file and run `bin/elasticsearch` (or `bin\\elasticsearch.bat` on Windows). This will launch the ElasticSearch Server. Once the server is running, by default it's accessible at [localhost:9200](http://localhost:9200)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYVQqD16R2Ta"
   },
   "source": [
    "## Querying Elastic Search via Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdaDSaQIR2Tb"
   },
   "source": [
    "To make queries to ElasticSearch you can directly query the server endpoint via REST. However, we can make it easier via the the `elasticsearch-py` Python library. This library provides a wrapper for the REST endpoint that will allow us to query the server form Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcGWFnDG8gbM"
   },
   "source": [
    "In case you have not yet installed the libraries, you can execute the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "u0TlkWK78il7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: elasticsearch-dsl in c:\\users\\madcastea\\anaconda3\\lib\\site-packages (7.4.0)\n",
      "Requirement already satisfied: elasticsearch<8.0.0,>=7.0.0 in c:\\users\\madcastea\\anaconda3\\lib\\site-packages (from elasticsearch-dsl) (7.17.9)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\madcastea\\anaconda3\\lib\\site-packages (from elasticsearch-dsl) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\users\\madcastea\\anaconda3\\lib\\site-packages (from elasticsearch-dsl) (1.16.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\madcastea\\anaconda3\\lib\\site-packages (from elasticsearch<8.0.0,>=7.0.0->elasticsearch-dsl) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<2,>=1.21.1 in c:\\users\\madcastea\\anaconda3\\lib\\site-packages (from elasticsearch<8.0.0,>=7.0.0->elasticsearch-dsl) (1.26.11)\n",
      "Requirement already satisfied: elasticsearch in c:\\users\\madcastea\\anaconda3\\lib\\site-packages (7.17.9)\n",
      "Requirement already satisfied: certifi in c:\\users\\madcastea\\anaconda3\\lib\\site-packages (from elasticsearch) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<2,>=1.21.1 in c:\\users\\madcastea\\anaconda3\\lib\\site-packages (from elasticsearch) (1.26.11)\n"
     ]
    }
   ],
   "source": [
    "! pip install elasticsearch-dsl\n",
    "! pip install elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BgijtDO6R2Tb"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search, Q, Index\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wu2opfRWR2Tc"
   },
   "source": [
    "# Exercise 0: Indexing and Searching Demo for ElasticSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1S9BT4aMR2Tc"
   },
   "source": [
    "Now it's time to run some demo program. In this practice, we will create inverted index of sample documents (indexing) and then use Elasticsearch query grammar to search documents (searching)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oTQhr2oHR2Tc"
   },
   "source": [
    "### Useful functions\n",
    "\n",
    "Functions to facilitate the reading of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SYz7yuohR2Td"
   },
   "outputs": [],
   "source": [
    "import os, io\n",
    "from collections import namedtuple\n",
    "\n",
    "# A document class with following attributes\n",
    "# filename: document filename\n",
    "# text: body of documment\n",
    "# path: path of document\n",
    "Doc = namedtuple('Doc', 'filename path text')\n",
    "\n",
    "def read_doc(doc_path, encoding):\n",
    "    '''\n",
    "        reads a document from path\n",
    "        input:\n",
    "            - doc_path : path of document\n",
    "            - encoding: encoding\n",
    "        output: =>\n",
    "            - doc: instance of Doc namedtuple\n",
    "    '''\n",
    "    filename = doc_path.split('/')[-1]\n",
    "    fp = io.open(doc_path, 'r', encoding = encoding)\n",
    "    text = fp.read().strip()\n",
    "    fp.close()\n",
    "    return Doc(filename = filename, text = text, path = doc_path)\n",
    "\n",
    "def read_dataset(path, encoding = \"ISO-8859-1\"):\n",
    "    '''\n",
    "        reads multiple documents from path\n",
    "        input:\n",
    "            - doc_path : path of document\n",
    "            - encoding: encoding\n",
    "        output: =>\n",
    "            - docs: instances of Doc namedtuple returned as generator\n",
    "    '''\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for doc_path in files:\n",
    "            yield read_doc(root + '/' + doc_path, encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVIn8fFi8q9e"
   },
   "source": [
    "Setting up the connector\n",
    "\n",
    "To index the documents, we first need to make a connection to **Elasticsearch**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "I5R9m01u8wWQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Elasticsearch([{'host': 'localhost', 'port': 9020, 'use_ssl': True}])>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_conn = Elasticsearch(\n",
    "    'https://localhost:9020',\n",
    ")\n",
    "\n",
    "es_conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NxKDD2isR2Td"
   },
   "source": [
    "##  Indexing\n",
    "\n",
    "We will try to index the sample documents in `./sample_documents`. To index the documents, we first need to make a connection to **Elasticsearch**. \n",
    "\n",
    "Before we index the documents, we first need to define the **configuration of elasticsearch**. During this process, you can define basic configuration of indexer such as tokenizer, stemmer, lemmatizer, and also define which search algorithm elasticsearch will use for search.\n",
    "\n",
    "Below code shows a simple configuration settings for this demo.\n",
    "The configuration tells elasticsearch that our document `doc` will have three fields `filename`, `path`, and `text`, and we will use `text` field for search. `my_analyzer` will be used to parse the `text` field, and `my_analyzer` will also be used as a search analyzer, which will parse search queries later on. `index:False` in `filename` and `path` fields tell elasticsearch that we will not index these two fields, therefore, we cannot search these two fields with queries. \n",
    "\n",
    "The detailed documentation of analyzer can be found [here](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis.html).\n",
    "\n",
    "`\"similarity\": \"boolean\"` in `text` field will let elasticsearch know that we will use a boolean search algorithm to search `text` field. The detailed documentation of search algorithms can be found [here](https://www.elastic.co/guide/en/elasticsearch/reference/current/search.html)  and [here](https://www.elastic.co/guide/en/elasticsearch/guide/master/search-in-depth.html). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QKQP-AYJR2Te"
   },
   "outputs": [],
   "source": [
    "# configuration for indexing\n",
    "settings = {\n",
    "  \"mappings\": {\n",
    "      \"properties\": {\n",
    "        \"filename\": {\n",
    "          \"type\": \"keyword\",\n",
    "          \"index\": False,\n",
    "        },\n",
    "        \"path\": {\n",
    "          \"type\": \"keyword\",\n",
    "          \"index\": False,\n",
    "        },\n",
    "        \"text\": {\n",
    "          \"type\": \"text\",\n",
    "          \"similarity\": \"boolean\",\n",
    "          \"analyzer\": \"my_analyzer\",\n",
    "          \"search_analyzer\": \"my_analyzer\"\n",
    "        }\n",
    "      }\n",
    "  },    \n",
    "  \"settings\": {      \n",
    "    \"analysis\": {\n",
    "      \"analyzer\": {\n",
    "        \"my_analyzer\": {\n",
    "          \"filter\": [\n",
    "            \"lowercase\",\"stop\"\n",
    "          ],\n",
    "          \"type\": \"custom\",\n",
    "          \"tokenizer\": \"whitespace\",\n",
    "          \"char_filter\": [\"my_char_filter\"]\n",
    "        }\n",
    "      },\n",
    "      \"char_filter\": {\n",
    "        \"my_char_filter\": {\n",
    "          \"type\": \"html_strip\",\n",
    "          \"escaped_tags\": [\"b\"]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1VAeUGsR2Tf"
   },
   "source": [
    "Now we will retrieve `sample documents` and indexing them into `INDEX_NAME` index. To that end, the following 2 functions will help you in the creation of the index and the indexing of the documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [],
    "id": "boLy6mbMR2Tf"
   },
   "outputs": [],
   "source": [
    "ES_HOSTS = ['http://localhost:9200']\n",
    "INDEX_NAME = 'sample_index'\n",
    "DOCS_PATH = 'practice_data/sample_documents'\n",
    "\n",
    "def create_index(es_conn, index_name, settings):\n",
    "    '''\n",
    "        create index structure in elasticsearch server. \n",
    "        If index_name exists in the server, it will be removed, and new index will be created.\n",
    "        input:\n",
    "            - es_conn: elasticsearch connection object\n",
    "            - index_name: name of index to create\n",
    "            - settings: settings and mappings for index to create\n",
    "        output: =>\n",
    "            - None\n",
    "    '''\n",
    "    if es_conn.indices.exists(index_name):\n",
    "        es_conn.indices.delete(index = index_name)\n",
    "        print('index `{}` deleted'.format(index_name))\n",
    "    es_conn.indices.create(index = index_name, body = settings)\n",
    "    print('index `{}` created'.format(index_name))            \n",
    "            \n",
    "def build_index(es_conn, dataset, index_name, settings, DOC_TYPE='doc'):\n",
    "    '''\n",
    "        build index from a collection of documents\n",
    "        input:\n",
    "            - es_conn: elasticsearch connection object\n",
    "            - dataset: iterable, collection of namedtuple Doc objects\n",
    "            - index_name: name of the index where the documents will be stored\n",
    "            - DOC_TYPE: type signature of documents\n",
    "    '''\n",
    "    # create the index if it doesn't exist\n",
    "    create_index(es_conn = es_conn, index_name = index_name, settings=settings)\n",
    "    counter_read, counter_idx_failed = 0, 0 # counters\n",
    "\n",
    "    # retrive & index documents\n",
    "    for doc in dataset:\n",
    "        res = es_conn.index(\n",
    "            index = index_name,\n",
    "            id = doc.filename,\n",
    "            body = doc._asdict())\n",
    "        counter_read += 1\n",
    "\n",
    "        if res['result'] != 'created':\n",
    "            conter_idx_failed += 1\n",
    "        elif counter_read % 500 == 0:\n",
    "            print('indexed {} documents'.format(counter_read))\n",
    "\n",
    "    print('indexed {} docs to index `{}`, failed to index {} docs'.format(\n",
    "        counter_read,\n",
    "        index_name,\n",
    "        counter_idx_failed\n",
    "    ))\n",
    "    \n",
    "    # refresh after indexing\n",
    "    es_conn.indices.refresh(index=index_name)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c-wy9poS9BEc"
   },
   "outputs": [],
   "source": [
    "dataset = read_dataset(DOCS_PATH)\n",
    "build_index(es_conn, dataset, INDEX_NAME, settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ypg5F-J2R2Th"
   },
   "source": [
    "We successfully created an inverted index for the sample documents in `./sample/documents`. It's time to search the documents with some queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e19wVK1VR2Ti"
   },
   "source": [
    "## Searching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ve4_3QhrR2Ti"
   },
   "source": [
    "### Full-Text Search\n",
    "\n",
    "The two most important aspects of full-text search are as follows:\n",
    "\n",
    "##### Relevance\n",
    "\n",
    ">The ability to rank results by how relevant they are to the given query, whether relevance is calculated using TF/IDF (see [What Is Relevance?](https://www.elastic.co/guide/en/elasticsearch/guide/master/relevance-intro.html)), proximity to a geolocation, fuzzy similarity, or some other algorithm.\n",
    "\n",
    "##### Analysis\n",
    "\n",
    ">The process of converting a block of text into distinct, normalized tokens (see [Analysis and Analyzers](https://www.elastic.co/guide/en/elasticsearch/guide/master/analysis-intro.html) in order to (a) create an inverted index and (b) query the inverted index.\n",
    "\n",
    "#### Term-Based Versus Full-Text\n",
    "\n",
    "Two types of text query:\n",
    "\n",
    "##### Term-based\n",
    "\n",
    "Queries like the term or fuzzy queries are low-level queries that have no analysis phase. They operate on a single term. A term query for the term Foo looks for that exact term in the inverted index and calculates the TF/IDF relevance _score for each document that contains the term.\n",
    "\n",
    "##### Full-text queries\n",
    "\n",
    "Queries like the match or query_string queries are high-level queries that understand the mapping of a field:\n",
    "\n",
    "* If you use them to query a date or integer field, they will treat the query string as a date or integer, respectively.\n",
    "\n",
    "* If you query an exact value (not_analyzed) string field, they will treat the whole query string as a single term.\n",
    "\n",
    "* But if you query a full-text (analyzed) field, they will first pass the query string through the appropriate analyzer to produce the list of terms to be queried.\n",
    "\n",
    "Once the query has assembled a list of terms, it executes the appropriate low-level query for each of these terms, and then combines their results to produce the final relevance score for each document.\n",
    "\n",
    "#### The match Query\n",
    "\n",
    "We will perform now different types of queries.\n",
    "\n",
    "First, a query with a single term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DzX9kKroR2Tj"
   },
   "outputs": [],
   "source": [
    "s = Search(using=es_conn, index=\"sample_index\")\n",
    "s = s.query(\"match\", text={\"query\": \"obama\"})\n",
    "res = s.execute()\n",
    "\n",
    "for hit in res:\n",
    "    print(hit.filename, hit.text[:100], '... - Score:', hit.meta.score)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7zDrHxf9W6a"
   },
   "source": [
    "#### Multiword Queries\n",
    "\n",
    "Obviously, we can search on more than one word at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EZxm1QE_9W6a",
    "outputId": "9ce7a675-28fd-445b-b261-65ebcc9be8af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc1.txt Barack Hussein Obama II (born August 4, 1961) is the 44th and current President of the United States, the first African American to hold the office. He served as the junior United States Senator from  ... - Score: 2.0\n",
      "\n",
      "doc2.txt Michelle LaVaughn Robinson Obama (born January 17, 1964) is the wife of the forty-fourth President of the United States, Barack Obama, and is the first African-American First Lady of the United States ... - Score: 1.0\n",
      "\n",
      "doc3.txt Joseph Robinette \"Joe\" Biden, Jr. (born November 20, 1942) is the 47th and current Vice President of the United States. He was a United States Senator from Delaware from January 3, 1973 until his resi ... - Score: 1.0\n",
      "\n",
      "doc4.txt Hillary Diane Rodham Clinton (born October 26, 1947) is the 67th United States Secretary of State, serving within the administration of President Barack Obama. She was a United States Senate from New  ... - Score: 1.0\n",
      "\n",
      "doc5.txt John Sidney McCain III (born August 29, 1936) is the senior United States Senator from Arizona. He was the Republican nominee for president in the 2008 United States election.\n",
      "\n",
      "McCain followed his fat ... - Score: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = Search(using=es_conn, index=\"sample_index\")\n",
    "s = s.query(\"match\", text={\"query\":    \"Obama Hillary\"})\n",
    "res = s.execute()\n",
    "\n",
    "for hit in res:\n",
    "    print(hit.filename, hit.text[:200], '... - Score:', hit.meta.score)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Prsjaad9W6a"
   },
   "source": [
    "The important thing is: any document whose title field contains at least one of the specified terms will match the query. The more terms that match, the more relevant the document.\n",
    "\n",
    "But what happens if I want both terms appearing in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hiLZsbxs9W6a",
    "outputId": "ecf1b4f2-04f2-438b-e616-136d43a75cd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc1.txt Barack Hussein Obama II (born August 4, 1961) is the 44th and current President of the United States, the first African American to hold the office. He served as the junior United States Senator from Illinois from January 2005 until he resigned after his election to the presidency in November 2008.\n",
      "\n",
      "Obama is a graduate of Columbia University and Harvard Law School, where he was the president of the Harvard Law Review. He was a community organizer in Chicago before earning his law degree. He worked as a civil rights attorney in Chicago and also taught constitutional law at the University of Chicago Law School from 1992 to 2004.\n",
      "\n",
      "Obama served three terms in the Illinois Senate from 1997 to 2004. Following an unsuccessful bid for a seat in the U.S. House of Representatives in 2000, Obama ran for United States Senate in 2004. His victory, from a crowded field, in the March 2004 Democratic primary raised his visibility. His prime-time televised keynote address at the Democratic National Convention in July 2004 made him a rising star nationally in the Democratic Party. He was elected to the U.S. Senate in November 2004 by the largest margin in the history of Illinois.\n",
      "\n",
      "He began his run for the presidency in February 2007. After a close campaign in the 2008 Democratic Party presidential primaries against Hillary Rodham Clinton, he won his party's nomination, becoming the first major party African American candidate for president. In the 2008 general election, he defeated Republican nominee John McCain and was inaugurated as president on January 20, 2009. ... - Score: 2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = Search(using=es_conn, index=\"sample_index\")\n",
    "s = s.query(\"match\", text={\n",
    "    \"query\":    \"Obama Hillary\",\n",
    "    \"operator\": \"and\"})\n",
    "res = s.execute()\n",
    "\n",
    "for hit in res:\n",
    "    print(hit.filename, hit.text, '... - Score:', hit.meta.score)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H5Ekget09W6b"
   },
   "source": [
    "And now containing a term but NOT the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7eRg6R8j9W6b",
    "outputId": "d2439420-f85b-4650-eeb3-4fe120c44b20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc4.txt Hillary Diane Rodham Clinton (born October 26, 1947) is the 67th United States Secretary of State, s ... - Score: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Boolean Query \"Obama BUT Hillary\"\n",
    "s = Search(using=es_conn, index=\"sample_index\")\n",
    "s = s.query(\"bool\", \n",
    "            must = [Q('match', text=\"hillary\")],\n",
    "            must_not = [Q('match', text=\"obama\")]\n",
    "           )\n",
    "\n",
    "res = s.execute()\n",
    "\n",
    "for hit in res:\n",
    "    print(hit.filename, hit.text[:100], '... - Score:', hit.meta.score)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "day1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
