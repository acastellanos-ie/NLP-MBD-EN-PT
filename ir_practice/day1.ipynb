{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "day1.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc4KKv4uR2TU"
      },
      "source": [
        "# Information Retrieval Practice\n",
        "\n",
        "Elasticsearch is an open-source distributed search server built on top of Apache Lucene. Itâ€™s a great tool that allows to quickly build applications with full-text search capabilities. The core implementation is in Java, but it provides a nice REST interface which allows to interact with Elasticsearch from any programming language.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y94Tw5_sR2TY"
      },
      "source": [
        "## Install Elastic Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_zghOWrR2TZ"
      },
      "source": [
        "To install elastic search download your the package for your platform from Get Elasticsearch\n",
        " in https://www.elastic.co/es/start\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEFHWtw9R2Ta"
      },
      "source": [
        "![](https://github.com/acastellanos-ie/natural_language_processing/blob/master/ir_practice/download.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_hMXNaPR2Ta"
      },
      "source": [
        "Once downloaded, unzip the tar.gz file and run `bin/elasticsearch` (or `bin\\elasticsearch.bat` on Windows). This will launch the ElasticSearch Server. Once the server is running, by default it's accessible at [localhost:9200](http://localhost:9200)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYVQqD16R2Ta"
      },
      "source": [
        "## Querying Elastic Search via Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdaDSaQIR2Tb"
      },
      "source": [
        "To make queries to ElasticSearch you can directly query the server endpoint via REST. However, we can make it easier via the the `elasticsearch-py` Python library. This library provides a wrapper for the REST endpoint that will allow us to query the server form Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgijtDO6R2Tb"
      },
      "source": [
        "from elasticsearch import Elasticsearch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu2opfRWR2Tc"
      },
      "source": [
        "# Exercise 0: Indexing and Searching Demo for ElasticSearch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1S9BT4aMR2Tc"
      },
      "source": [
        "Now it's time to run some demo program. In this practice, we will create inverted index of sample documents (indexing) and then use Elasticsearch query grammar to search documents (searching)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTQhr2oHR2Tc"
      },
      "source": [
        "### Useful functions\n",
        "\n",
        "Functions to facilitate the reading of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYz7yuohR2Td"
      },
      "source": [
        "import os, io\n",
        "from collections import namedtuple\n",
        "\n",
        "# A document class with following attributes\n",
        "# filename: document filename\n",
        "# text: body of documment\n",
        "# path: path of document\n",
        "Doc = namedtuple('Doc', 'filename path text')\n",
        "\n",
        "def read_doc(doc_path, encoding):\n",
        "    '''\n",
        "        reads a document from path\n",
        "        input:\n",
        "            - doc_path : path of document\n",
        "            - encoding: encoding\n",
        "        output: =>\n",
        "            - doc: instance of Doc namedtuple\n",
        "    '''\n",
        "    filename = doc_path.split('/')[-1]\n",
        "    fp = io.open(doc_path, 'r', encoding = encoding)\n",
        "    text = fp.read().strip()\n",
        "    fp.close()\n",
        "    return Doc(filename = filename, text = text, path = doc_path)\n",
        "\n",
        "def read_dataset(path, encoding = \"ISO-8859-1\"):\n",
        "    '''\n",
        "        reads multiple documents from path\n",
        "        input:\n",
        "            - doc_path : path of document\n",
        "            - encoding: encoding\n",
        "        output: =>\n",
        "            - docs: instances of Doc namedtuple returned as generator\n",
        "    '''\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for doc_path in files:\n",
        "            yield read_doc(root + '/' + doc_path, encoding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxKDD2isR2Td"
      },
      "source": [
        "##  Indexing\n",
        "\n",
        "We will try to index the sample documents in `./sample_documents`. To index the documents, we first need to make a connection to **Elasticsearch**. \n",
        "\n",
        "Before we index the documents, we first need to define the **configuration of elasticsearch**. During this process, you can define basic configuration of indexer such as tokenizer, stemmer, lemmatizer, and also define which search algorithm elasticsearch will use for search.\n",
        "\n",
        "Below code shows a simple configuration settings for this demo.\n",
        "The configuration tells elasticsearch that our document `doc` will have three fields `filename`, `path`, and `text`, and we will use `text` field for search. `my_analyzer` will be used to parse the `text` field, and `my_analyzer` will also be used as a search analyzer, which will parse search queries later on. `index:False` in `filename` and `path` fields tell elasticsearch that we will not index these two fields, therefore, we cannot search these two fields with queries. \n",
        "\n",
        "The detailed documentation of analyzer can be found [here](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis.html).\n",
        "\n",
        "`\"similarity\": \"boolean\"` in `text` field will let elasticsearch know that we will use a boolean search algorithm to search `text` field. The detailed documentation of search algorithms can be found [here](https://www.elastic.co/guide/en/elasticsearch/reference/current/search.html)  and [here](https://www.elastic.co/guide/en/elasticsearch/guide/master/search-in-depth.html). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKQP-AYJR2Te"
      },
      "source": [
        "# configuration for indexing\n",
        "settings = {\n",
        "  \"mappings\": {\n",
        "      \"properties\": {\n",
        "        \"filename\": {\n",
        "          \"type\": \"keyword\",\n",
        "          \"index\": False,\n",
        "        },\n",
        "        \"path\": {\n",
        "          \"type\": \"keyword\",\n",
        "          \"index\": False,\n",
        "        },\n",
        "        \"text\": {\n",
        "          \"type\": \"text\",\n",
        "          \"similarity\": \"boolean\",\n",
        "          \"analyzer\": \"my_analyzer\",\n",
        "          \"search_analyzer\": \"my_analyzer\"\n",
        "        }\n",
        "      }\n",
        "  },    \n",
        "  \"settings\": {      \n",
        "    \"analysis\": {\n",
        "      \"analyzer\": {\n",
        "        \"my_analyzer\": {\n",
        "          \"filter\": [\n",
        "            \"lowercase\",\"stop\"\n",
        "          ],\n",
        "          \"type\": \"custom\",\n",
        "          \"tokenizer\": \"whitespace\",\n",
        "          \"char_filter\": [\"my_char_filter\"]\n",
        "        }\n",
        "      },\n",
        "      \"char_filter\": {\n",
        "        \"my_char_filter\": {\n",
        "          \"type\": \"html_strip\",\n",
        "          \"escaped_tags\": [\"b\"]\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1VAeUGsR2Tf"
      },
      "source": [
        "Now we will retrieve `sample documents` and indexing them into `INDEX_NAME` index. To that end, the following 2 functions will help you in the creation of the index and the indexing of the documents.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "boLy6mbMR2Tf",
        "outputId": "532c44c0-fd4a-4b9e-c8de-1fa469458ce9"
      },
      "source": [
        "ES_HOSTS = ['http://localhost:9200']\n",
        "INDEX_NAME = 'sample_index'\n",
        "DOCS_PATH = 'practice_data/sample_documents'\n",
        "\n",
        "def create_index(es_conn, index_name, settings):\n",
        "    '''\n",
        "        create index structure in elasticsearch server. \n",
        "        If index_name exists in the server, it will be removed, and new index will be created.\n",
        "        input:\n",
        "            - es_conn: elasticsearch connection object\n",
        "            - index_name: name of index to create\n",
        "            - settings: settings and mappings for index to create\n",
        "        output: =>\n",
        "            - None\n",
        "    '''\n",
        "    if es_conn.indices.exists(index_name):\n",
        "        es_conn.indices.delete(index = index_name)\n",
        "        print('index `{}` deleted'.format(index_name))\n",
        "    es_conn.indices.create(index = index_name, body = settings)\n",
        "    print('index `{}` created'.format(index_name))            \n",
        "            \n",
        "def build_index(es_conn, dataset, index_name, settings, DOC_TYPE='doc'):\n",
        "    '''\n",
        "        build index from a collection of documents\n",
        "        input:\n",
        "            - es_conn: elasticsearch connection object\n",
        "            - dataset: iterable, collection of namedtuple Doc objects\n",
        "            - index_name: name of the index where the documents will be stored\n",
        "            - DOC_TYPE: type signature of documents\n",
        "    '''\n",
        "    # create the index if it doesn't exist\n",
        "    create_index(es_conn = es_conn, index_name = index_name, settings=settings)\n",
        "    counter_read, counter_idx_failed = 0, 0 # counters\n",
        "\n",
        "    # retrive & index documents\n",
        "    for doc in dataset:\n",
        "        res = es_conn.index(\n",
        "            index = index_name,\n",
        "            id = doc.filename,\n",
        "            body = doc._asdict())\n",
        "        counter_read += 1\n",
        "\n",
        "        if res['result'] != 'created':\n",
        "            counter_idx_failed += 1\n",
        "        elif counter_read % 500 == 0:\n",
        "            print('indexed {} documents'.format(counter_read))\n",
        "\n",
        "    print('indexed {} docs to index `{}`, failed to index {} docs'.format(\n",
        "        counter_read,\n",
        "        index_name,\n",
        "        counter_idx_failed\n",
        "    ))\n",
        "    \n",
        "    # refresh after indexing\n",
        "    es_conn.indices.refresh(index=index_name)  \n",
        "\n",
        "es_conn = Elasticsearch(ES_HOSTS)\n",
        "dataset = read_dataset(DOCS_PATH)\n",
        "build_index(es_conn, dataset, INDEX_NAME, settings)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "index `sample_index` deleted\n",
            "index `sample_index` created\n",
            "indexed 1 documents\n",
            "indexed 2 documents\n",
            "indexed 3 documents\n",
            "indexed 4 documents\n",
            "indexed 5 documents\n",
            "indexed 5 docs to index `sample_index`, failed to index 0 docs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ypg5F-J2R2Th"
      },
      "source": [
        "We successfully created an inverted index for the sample documents in `./sample/documents`. It's time to search the documents with some queries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e19wVK1VR2Ti"
      },
      "source": [
        "## Searching"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ve4_3QhrR2Ti"
      },
      "source": [
        "**Elasticsearch** supports a specific query grammar which intends to replicate the grammar of traditional search engines (Google Search supports a similar grammar).\n",
        "https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html\n",
        "\n",
        "To understand score of the result, check: https://www.elastic.co/guide/en/elasticsearch/guide/current/relevance-intro.html#explain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KMOZ4_TR2Ti"
      },
      "source": [
        "### Useful Functions\n",
        "\n",
        "These functions will help you with the ElasticSearch output format in order to visualize the search results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzX9kKroR2Tj"
      },
      "source": [
        "def extract_response(res):\n",
        "    if res is not None:\n",
        "        for hit in res['hits']['hits']:\n",
        "            filename = hit[\"_source\"][\"filename\"]\n",
        "            score = hit[\"_score\"]\n",
        "            \n",
        "            yield (filename, score)\n",
        "\n",
        "def print_result(query, res):\n",
        "    # formatter of searched result\n",
        "    matches = extract_response(res)\n",
        "    if matches is not None:\n",
        "        for match in sorted(matches, key = lambda x: -x[1]):\n",
        "            print('{}, {}, {},\\n'.format(\n",
        "                query,\n",
        "                match[0], # filename\n",
        "                match[1], # score\n",
        "            ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y54ZpJHeR2Tj"
      },
      "source": [
        "We will perform now different types of queries.\n",
        "\n",
        "First, a query with a single term"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o73-S8sR2Tj",
        "outputId": "dab7a4ac-baad-40a7-c2f9-70298853b2f2"
      },
      "source": [
        "res = es_conn.search(index = INDEX_NAME,\n",
        "    body={\n",
        "          \"query\": {\n",
        "            \"bool\": {\n",
        "              \"must\": [\n",
        "                {\n",
        "                  \"match\": {\"text\": \"Obama\"}\n",
        "                }\n",
        "              ]\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "    )\n",
        "print_result(\"Obama\", res)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obama, doc1.txt, 1.0,\n",
            "\n",
            "Obama, doc3.txt, 1.0,\n",
            "\n",
            "Obama, doc5.txt, 1.0,\n",
            "\n",
            "Obama, doc2.txt, 1.0,\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiDeCrFCR2Tk"
      },
      "source": [
        "Now a query for the documents containing both terms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxJIYYNaR2Tk",
        "outputId": "fe37043c-1618-46bf-9f58-cd800ec6d31f"
      },
      "source": [
        "# Boolean Query \"Obama AND Hillary\"\n",
        "res = es_conn.search(index = INDEX_NAME,\n",
        "    body={\n",
        "          \"query\": {\n",
        "            \"match\" : {\n",
        "              \"text\" : {\n",
        "                \"query\" : \"Obama Hillary\",\n",
        "                \"operator\" : \"and\"\n",
        "              }\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "    )\n",
        "print_result(\"Obama AND Hillary\", res)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obama AND Hillary, doc1.txt, 2.0,\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQtXbSGbR2Tl"
      },
      "source": [
        "And now containing a term but NOT the other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbSWNbgdR2Tl",
        "outputId": "f6742c68-b56c-4dc0-c689-be88215fd3b3"
      },
      "source": [
        "# Boolean Query \"Obama BUT Hillary\"\n",
        "res = es_conn.search(index = INDEX_NAME,\n",
        "    body={\n",
        "          \"query\": {\n",
        "            \"bool\": {\n",
        "              \"must\": [\n",
        "                {\n",
        "                    \"match\": {\"text\": \"Obama\"}\n",
        "                }\n",
        "              ],\n",
        "              \"must_not\":[\n",
        "                {\n",
        "                    \"match\": {\"text\": \"Hillary\"}\n",
        "                }\n",
        "              ]\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "    )\n",
        "print_result(\"Obama BUT Hillary\", res)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obama BUT Hillary, doc3.txt, 1.0,\n",
            "\n",
            "Obama BUT Hillary, doc5.txt, 1.0,\n",
            "\n",
            "Obama BUT Hillary, doc2.txt, 1.0,\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ua-T2OdsR2Tl"
      },
      "source": [
        "Finally, the default behaviour for queries with more than one term: OR."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2nurql0R2Tm",
        "outputId": "5c6f3ef8-1173-42f5-aea5-c12fd846eb57"
      },
      "source": [
        "# Boolean Query \"Obama OR Hillary\"\n",
        "# default is OR\n",
        "res = es_conn.search(index = INDEX_NAME,\n",
        "    body={\n",
        "          \"query\": {\n",
        "            \"match\" : {\n",
        "              \"text\" : {\n",
        "                \"query\" : \"Obama Hillary\",\n",
        "              }\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "    )\n",
        "print_result(\"Obama OR Hillary\", res)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obama OR Hillary, doc1.txt, 2.0,\n",
            "\n",
            "Obama OR Hillary, doc3.txt, 1.0,\n",
            "\n",
            "Obama OR Hillary, doc5.txt, 1.0,\n",
            "\n",
            "Obama OR Hillary, doc4.txt, 1.0,\n",
            "\n",
            "Obama OR Hillary, doc2.txt, 1.0,\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}