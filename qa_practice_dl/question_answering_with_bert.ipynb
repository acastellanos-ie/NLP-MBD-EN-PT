{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "question_answering_with_bert.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acastellanos-ie/NLP-MBD-EN-PT-2021-J-1/blob/main/qa_practice_dl/question_answering_with_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coUhsrt20sOI"
      },
      "source": [
        "# Google Colab Configuration\n",
        "\n",
        "**Execute this steps to configure the Google Colab environment in order to execute this notebook. It is not required if you are executing it locally and you have properly configured your local environment according to what explained in the Github Repository.**\n",
        "\n",
        "The first step is to clone the repository to have access to all the data and files."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "repository_name = \"NLP-MBD-EN-PT-2021-J-1\"\n",
        "repository_url = 'https://github.com/acastellanos-ie/' + repository_name"
      ],
      "metadata": {
        "id": "gakj_n0h70ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d7mC64KvlwP",
        "outputId": "e5cb877b-fee1-4be7-f1bf-343f2fba42a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! git clone $repository_url"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MBD-EN-BL-ENE-2020-J-1'...\n",
            "remote: Enumerating objects: 4481, done.\u001b[K\n",
            "remote: Counting objects: 100% (4481/4481), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4368/4368), done.\u001b[K\n",
            "remote: Total 4481 (delta 158), reused 4387 (delta 94), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (4481/4481), 13.41 MiB | 19.53 MiB/s, done.\n",
            "Resolving deltas: 100% (158/158), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ecfec2Y4v6e9"
      },
      "source": [
        "Install the requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIep7l0jvtUB",
        "outputId": "d45eba5a-9325-44ed-ae93-ebf4493fa51a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! pip install -Uqqr $repository_name/requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.5MB 9.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.4MB 1.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 12.0MB 170kB/s \n",
            "\u001b[K     |████████████████████████████████| 9.9MB 42.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 348kB 44.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 49.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 727kB 24.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 454.3MB 35kB/s \n",
            "\u001b[K     |████████████████████████████████| 25.3MB 1.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 10.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.3MB 29.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.8MB 36.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 58.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 8.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 52.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0MB 33.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.0MB 26.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 471kB 53.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 44.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0MB 23.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 983kB 57.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 266kB 22.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 471kB 42.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3MB 23.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 901kB 45.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.9MB 37.5MB/s \n",
            "\u001b[?25h  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for eli5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for stellargraph (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for networkx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for syntok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement gast==0.3.3, but you'll have gast 0.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement grpcio~=1.32.0, but you'll have grpcio 1.34.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement h5py~=2.10.0, but you'll have h5py 3.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement tensorflow-estimator<2.5.0,>=2.4.0, but you'll have tensorflow-estimator 2.5.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 1.2.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: ktrain 0.26.2 has requirement scikit-learn==0.23.2, but you'll have scikit-learn 0.22.2.post1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: ktrain 0.26.2 has requirement transformers<=4.3.3,>=4.0.0, but you'll have transformers 4.6.0 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKqBBIxf03lS"
      },
      "source": [
        "Ensure that you have the GPU runtime activated:\n",
        "\n",
        "![](https://miro.medium.com/max/3006/1*vOkqNhJNl1204kOhqq59zA.png)\n",
        "\n",
        "Now you have everything you need to execute the code in Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1N8KclZDwPY"
      },
      "source": [
        "# Building an End-to-End Question-Answering System With BERT\n",
        "\n",
        "In this notebook, we build a practical, end-to-end Question-Answering (QA) system with BERT in rougly 3 lines of code.  We will treat a corpus of text documents as a knowledge base to which we can ask questions and retrieve exact answers using [BERT](https://arxiv.org/abs/1810.04805). This goes beyond simplistic keyword searches.\n",
        "\n",
        "For this example, we will use the [20 Newsgroup dataset](http://qwone.com/~jason/20Newsgroups/) as the text corpus.  As a collection of newsgroup postings which contains an abundance of opinions and debates, the corpus is not ideal as a knowledgebase.  It is better to use fact-based documents such as Wikipedia articles or even news articles.  However, this dataset will suffice for this example.\n",
        "\n",
        "Let us begin by loading the dataset into an array using **scikit-learn** and importing *ktrain* modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uupMqRf7DwPa"
      },
      "source": [
        "# load 20newsgroups datset into an array\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "remove = ('headers', 'footers', 'quotes')\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', remove=remove)\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', remove=remove)\n",
        "docs = newsgroups_train.data +  newsgroups_test.data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QebfGvV7DwPc"
      },
      "source": [
        "# ! pip install ktrain\n",
        "\n",
        "import ktrain\n",
        "from ktrain import text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6kkPDprDwPc"
      },
      "source": [
        "### STEP 1:  Index the Documents\n",
        "\n",
        "We will first index the documents into a search engine that will be used to quickly retrieve documents that are likely to contain answers to a question. To do so, we must choose an index location, which must be a folder that does not already exist. \n",
        "\n",
        "Since the newsgroup postings are small and fit in memory, we wil set `commit_every` to a large value to speed up the indexing process. This means results will not be written until the end.  If you experience issues, you can lower this value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8oZ3TNlDwPd"
      },
      "source": [
        "INDEXDIR = '/tmp/myindex'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "k0DNRaPeDwPe",
        "outputId": "9cebcd5b-5f43-48cb-973d-11a775331c6a"
      },
      "source": [
        "text.SimpleQA.initialize_index(INDEXDIR)\n",
        "text.SimpleQA.index_from_list(docs, INDEXDIR, commit_every=len(docs),\n",
        "                              multisegment=True, procs=4, # these args speed up indexing\n",
        "                               breakup_docs=True         # this slows indexing but speeds up answer retrieval\n",
        "                              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKu0RIpIDwPf"
      },
      "source": [
        "For documents sets that are too large to be loaded into a Python list, you can use `SimpleQA.index_from_folder`, which will crawl a folder and index all plain text documents (e.g.,, `.txt` files) by default.  If your documents are in formats like `.pdf`, `.docx`, or `.pptx`, you can supply the `use_text_extraction=True` argument to `index_from_folder`, which will use the [textract](https://textract.readthedocs.io/en/stable/) package to extract text from different file types and index this text into the search engine for answer rerieval.  You can also manually convert them to `.txt` files with the  `ktrain.text.textutils.extract_copy` or tools like [Apache Tika](https://tika.apache.org/) or [textract](https://textract.readthedocs.io/en/stable/).  \n",
        "\n",
        "#### Speeding Up Indexing\n",
        "By default, `index_from_list` and `index_from_folder` use a single processor (`procs=1`) with each processor using a maximum of 256MB of memory (`limitmb=256`) and merging results into a single segment (`multisegment=False`).  These values can be changed to speedup indexing as arguments to `index_from_list` or `index_from_folder`.  See the [whoosh documentation](https://whoosh.readthedocs.io/en/latest/batch.html) for more information on these parameters and how to use them to speedup indexing.  In this case, we've used `multisegment=True` and `procs=4`.\n",
        "\n",
        "#### Speeding Up Answer Retrieval\n",
        "\n",
        "Note that larger documents will cause inferences in STEP 3 (see below) to be very slow.  If your dataset consists of larger documents (e.g., long articles), we recommend breaking them up into pages (e.g., splitting the original PDF using something like `pdfseparate`) or splitting them into paragraphs (paragraphs are probably preferrable).  The latter can be done with *ktrain* using:\n",
        "```python\n",
        "ktrain.text.textutils.paragraph_tokenize(document, join_sentences=True)\n",
        "```\n",
        "If you supply `breakup_docs=True` in the cell above, this will be done automatically.  Note that `breakup_docs=True` will slightly **slow indexing** (i.e., STEP 1), but **speed up answer retrieval** (i.e., STEP 3 below).  A second way to speed up answer-retrieval is to increase `batch_size` in STEP 3 if using a GPU, which will be discussed later.\n",
        "\n",
        "\n",
        "The above steps need to only be performed once. Once an index is already created, you can skip this step and proceed directly to **STEP 2** to begin using your system."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JB1dsZU-DwPh"
      },
      "source": [
        "### STEP 2: Create a QA instance\n",
        "\n",
        "Next, we create a QA instance.  This step will automatically download the BERT SQuAD model if it does not already exist on your system."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_X2morirDwPh"
      },
      "source": [
        "qa = text.SimpleQA(INDEXDIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pecSWFPCDwPi"
      },
      "source": [
        "That's it!  In roughly **3 lines of code**, we have built an end-to-end QA system that can now be used to generate answers to questions.  Let's ask our system some questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0pqyBRBDwPi"
      },
      "source": [
        "### STEP 3:  Ask Questions\n",
        "\n",
        "We will invoke the `ask` method to issue questions to the text corpus we indexed and retrieve answers.  We will also use the `qa.display` method to nicely display the top 5 results in this Jupyter notebook. The answers are inferred using a BERT model fine-tuned on the SQuAD dataset.  The model will comb through paragraphs and sentences to find candidate answers. By default, `ask` currently uses a `batch_size` of 8, but, if necessary, you can experiment with lowering it by setting the `batch_size` parameter.  On a CPU, for instance, you may want to try `batch_size=1`.\n",
        "\n",
        "Note also that the 20 Newsgroup Dataset covers events in the early to mid 1990s, so references to recent events will not exist.\n",
        "\n",
        "#### Space Question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "5h7xaf7XDwPk",
        "outputId": "ca29f148-4397-4156-cecb-068671a92bf0"
      },
      "source": [
        "answers = qa.ask('When did the Cassini probe launch?')\n",
        "qa.display_answers(answers[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Candidate Answer</th>\n",
              "      <th>Context</th>\n",
              "      <th>Confidence</th>\n",
              "      <th>Document Reference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>in october of 1997</td>\n",
              "      <td><div> cassini is scheduled for launch aboard a titan iv / centaur  <font color='red'>in october of 1997</font> .</div></td>\n",
              "      <td>0.819032</td>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>on january 26,1962</td>\n",
              "      <td><div>ranger 3, launched  <font color='red'>on january 26,1962</font> , was intended to land an instrument capsule on the surface of the moon, but problems during the launch caused the probe to miss the moon and head into solar orbit.</div></td>\n",
              "      <td>0.151230</td>\n",
              "      <td>8525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>- 10 / 06 / 97</td>\n",
              "      <td><div>key scheduled dates for the cassini mission (vvejga trajectory)-------------------------------------------------------------10 / 06 / 97-titan iv / centaur launch 04 / 21 / 98-venus 1 gravity assist 06 / 20 / 99-venus 2 gravity assist 08 / 16 / 99-earth gravity assist 12 / 30 / 00-jupiter gravity assist 06 / 25 / 04-saturn arrival 01 / 09 / 05-titan probe release 01 / 30 / 05-titan probe entry 06 / 25 / 08-end of primary mission (schedule last updated 7 / 22 / 92) <font color='red'>- 10 / 06 / 97</font> </div></td>\n",
              "      <td>0.029694</td>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>* 98</td>\n",
              "      <td><div> cassini * * * * * * * * * * * * * * * * *  <font color='red'>* 98</font> ,115 * * * *</div></td>\n",
              "      <td>0.000026</td>\n",
              "      <td>5356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>the latter part of the 1990s</td>\n",
              "      <td><div> scheduled for launch in  <font color='red'>the latter part of the 1990s</font> , the craf and cassini missions are a collaborative project of nasa, the european space agency and the federal space agencies of germany and italy, as well as the united states air force and the department of energy.</div></td>\n",
              "      <td>0.000017</td>\n",
              "      <td>18684</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFPT4kJ7DwPl"
      },
      "source": [
        "As you can see, the top candidate answer indicates that the Cassini space probe was launched in October of 1997, which appears to be correct.  The correct answer will not always be the top answer, but it is in this case.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeqDLTvFDwPm"
      },
      "source": [
        "The 20 Newsgroup dataset contains lots of posts discussing and debating religions like Christianity and Islam, as well.  Let's ask a question on this subject.\n",
        "\n",
        "#### Religious Question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "qoYpcSzPDwPn",
        "outputId": "bbbc183d-f9ac-48de-92cc-c68a27b078e7"
      },
      "source": [
        "answers = qa.ask('Who was Muhammad?')\n",
        "qa.display_answers(answers[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Candidate Answer</th>\n",
              "      <th>Context</th>\n",
              "      <th>Confidence</th>\n",
              "      <th>Document Reference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the holy prophet of islam</td>\n",
              "      <td><div>just a small reminder to all my muslim brothers, did _ ever _  <font color='red'>the holy prophet of islam</font>  (muhammad pbuh), say to anyone who called himself a muslim :</div></td>\n",
              "      <td>0.762461</td>\n",
              "      <td>1278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the messenger of allah</td>\n",
              "      <td><div> muhammad is  <font color='red'>the messenger of allah</font> , and those who are with him are firm against the unbelievers and merciful among each other.</div></td>\n",
              "      <td>0.201865</td>\n",
              "      <td>4876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>is the last prophet of islam</td>\n",
              "      <td><div>muhammad peace and blessings of allah be upon him (saw)  <font color='red'>is the last prophet of islam</font> .</div></td>\n",
              "      <td>0.035121</td>\n",
              "      <td>4640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>either a liar, or he was crazy (a modern day mad mahdi) or he was actually who he said he was</td>\n",
              "      <td><div>the book says that muhammad was  <font color='red'>either a liar, or he was crazy (a modern day mad mahdi) or he was actually who he said he was</font> .</div></td>\n",
              "      <td>0.000293</td>\n",
              "      <td>4934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[ mahound ' s</td>\n",
              "      <td><div> muhammad ' s  <font color='red'>[ mahound ' s</font>  ] integrity is not really impugned in this part of the story, and there ' s no reason to think this was rushdie ' s intent : gibreel, as the archangel, produces the verses (divine and satanic), though he does not know their provenance.</div></td>\n",
              "      <td>0.000138</td>\n",
              "      <td>15852</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjVPgcGRDwPo"
      },
      "source": [
        "Here, we see different views on who Muhammad, the founder of Islam, as debated and discussed in this document set. \n",
        "\n",
        "Finally, the 20 Newsgroup dataset also contains many groups about computing hardware and software.  Let's ask a technical support question.\n",
        "\n",
        "#### Technical Question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "CgCzCUzwDwPo",
        "outputId": "acc3785a-94b8-4079-89ed-f228cce29828"
      },
      "source": [
        "answers = qa.ask('What causes computer images to be too dark?')\n",
        "qa.display_answers(answers[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Candidate Answer</th>\n",
              "      <th>Context</th>\n",
              "      <th>Confidence</th>\n",
              "      <th>Document Reference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>if your viewer does not do gamma correction</td>\n",
              "      <td><div> <font color='red'>if your viewer does not do gamma correction</font> , then linear images will look too dark, and gamma corrected images will ok.</div></td>\n",
              "      <td>0.937990</td>\n",
              "      <td>13873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>is gamma correction</td>\n",
              "      <td><div> this,  <font color='red'>is gamma correction</font>  (or the lack of it).</div></td>\n",
              "      <td>0.045165</td>\n",
              "      <td>13873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>so if you just dump your nice linear image out to a crt</td>\n",
              "      <td><div> <font color='red'>so if you just dump your nice linear image out to a crt</font> , the image will look much too dark.</div></td>\n",
              "      <td>0.010337</td>\n",
              "      <td>13873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>that small color details</td>\n",
              "      <td><div> the algorithm achieves much of its compression by exploiting known limitations of the human eye, notably the fact  <font color='red'>that small color details</font>  are not perceived as well as small details of light and dark.</div></td>\n",
              "      <td>0.002115</td>\n",
              "      <td>16207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>that small color details</td>\n",
              "      <td><div> the algorithm achieves much of its compression by exploiting known limitations of the human eye, notably the fact  <font color='red'>that small color details</font>  are not perceived as well as small details of light and dark.</div></td>\n",
              "      <td>0.002115</td>\n",
              "      <td>6987</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpadG3RTDwPp"
      },
      "source": [
        "As you can see, a lack of *gamma correction* is the top answer.\n",
        "\n",
        "\n",
        "### Using `SimpleQA` as a Simple Search Engine\n",
        "Once an index is created, `SimpleQA` can also be used as a conventional search engine to perform keyword searches using the `search` method:\n",
        "\n",
        "See the [whoosh documentation](https://whoosh.readthedocs.io/en/latest/querylang.html) for more information on query syntax.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPqY4EdIDwPt",
        "outputId": "47a40c8f-b2cc-48b5-9c7f-bcb448410f91"
      },
      "source": [
        "qa.search(' \"solar orbit\" AND \"battery power\" ') # find documents that contain both these phrases"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'rawtext': 'RANGER 5 , launched October 18 , 1962 and similar to RANGER 3 and 4 , lost all solar panel and battery power enroute and eventually missed the Moon and drifted off into solar orbit .',\n",
              "  'reference': '8525'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}